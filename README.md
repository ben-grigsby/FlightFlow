# HermesFlow

**End-to-End Data Engineering & ML Pipeline for Global Flight Data**

---

## Purpose

HermesFlow is designed to help **airlines and airports** organize and analyze global flight information efficiently.  
In particular, it focuses on **JFK Airport**, where it predicts **arrival delays** for incoming flights up to **eight days in advance**.  
Flight data is retrieved from the **AviationStack API**, which allows access to schedules up to **eight days in the future** â€” the earliest window available for forecasting.  

This capability is critical for **resource planning, gate allocation, and passenger communication**, making the system not just a technical showcase but a **practical decision-support tool** for aviation operations.

---

HermesFlow is a full-scale data engineering project that continuously ingests and processes real-world flight data using the AviationStack API.  

It combines stream-style ingestion, batch ETL, Airflow orchestration, and machine learning prediction to forecast future flight delays â€” all organized within a modern Medallion Architecture (Bronze â†’ Silver â†’ Gold).

---

## Table of Contents

1. [Features](#features)  
2. [Folder Structure](#folder-structure)  
3. [Core Components](#core-components)  
4. [ETL Pipeline (Bronze â†’ Silver â†’ Gold)](#etl-pipeline-bronze--silver--gold)  
5. [Setup](#setup)  
6. [DAG Scheduling Summary](#dag-scheduling-summary)  
7. [Future Enhancements](#future-enhancements)  
8. [Project Reflection](#project-reflection)
9. [Author](#author)

---

## Features

- **Kafka-Based Data Ingestion**:  
  - AviationStack flight data (historical and future) is streamed into Kafka topics.  
  - Kafka acts as a resilient buffer, decoupling data ingestion from processing.  

- **Dual Pipelines**:  
  - **Historical Flights DAG** â€” Pulls previous dayâ€™s flight data and stores it in an Apache Iceberg table.  
  - **Future Flights DAG** â€” Fetches scheduled flights 8 days ahead and predicts their expected delays using an XGBoost model.

- **ETL Pipeline**:  
  - Raw JSON (Bronze) â†’ Cleaned Parquet (Silver) â†’ Iceberg & Predictions (Gold).  

- **ML Integration**:  
  - Weekly retraining on historical data with PySpark + XGBoost.  
  - Daily inference pipeline predicting future arrival delays.  

- **Airflow Orchestration**:  
  - Manages ingestion, transformation, model retraining, and prediction.  

- **Logging & Monitoring**:  
  - Built-in Airflow and Python logging across all tasks.  

- **Scalable Architecture**:  
  - Modularized structure for distributed data engineering and ML processing.

---

## Folder Structure

```
HermesFlow/
â”œâ”€â”€ dags/                            # Airflow DAG definitions
â”‚   â”œâ”€â”€ avstack_daily_data_dag.py    # Historical flight data pipeline
â”‚   â”œâ”€â”€ avstack_future_flight_delay_prediction_dag.py  # Future prediction pipeline
â”‚
â”œâ”€â”€ dashboard/                       # Dashobard definitions
â”‚   â”œâ”€â”€ load_data.py                 # Loads in data from iceberg warehouse
â”‚   â”œâ”€â”€ main.py                      # Full code and structure for the dashboard
â”‚
â”œâ”€â”€ scripts/                         # Python scripts for ingestion, ML, and utils
â”‚   â”œâ”€â”€ avstack/
â”‚   â”‚   â”œâ”€â”€ avstack_kafka_producer.py
â”‚   â”‚   â”œâ”€â”€ avstack_kafka_consumer.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â””â”€â”€ modeling/
â”‚       â”œâ”€â”€ train_model.py           # Retrains weekly XGBoost model
â”‚       â”œâ”€â”€ predict_future.py        # Predicts future flight delays
â”‚       â””â”€â”€ email_predictions.py     # (Optional) Sends predictions via email
â”‚
â”œâ”€â”€ etl/                             # Modular ETL scripts for each layer
â”‚   â”œâ”€â”€ future_data/
â”‚   â”‚   â”œâ”€â”€ future_data_etl.py
â”‚   â”‚   â””â”€â”€ future_data_encoding.py
â”‚   â””â”€â”€ daily_data/
â”‚       â”œâ”€â”€ daily_data_etl.py
â”‚       â””â”€â”€ daily_data_encoding.py
â”‚
â”œâ”€â”€ data/                            # Output data directory (mounted volume)
â”‚   â”œâ”€â”€ bronze/                      # Raw JSON from AviationStack
â”‚   â”œâ”€â”€ silver/                      # Cleaned and structured parquet files
â”‚   â”œâ”€â”€ gold/                        # Final Iceberg tables and predictions
â”‚   â”œâ”€â”€ models/                      # Trained ML models
â”‚   â””â”€â”€ predictions_excel/           # Excel exports of delay forecasts
â”‚
â”œâ”€â”€ docker-compose.yml               # Airflow, Kafka, Postgres setup
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ PROJECT_REFLECTION.md            # Deep reflection about tool choices, motivations, and other insights
â””â”€â”€ .env                             # API keys and config variables
```

---

## Core Components

### 1. Kafka Streaming Backbone
- Kafka handles **real-time ingestion and buffering** of AviationStack data.  
- The **producer** (`avstack_kafka_producer.py`) fetches API data and publishes JSON payloads into a Kafka topic which begins the **Bronze layer**.  
- The **consumer** (`avstack_kafka_consumer.py`) reads from that topic, writing structured messages to end the **Bronze layer**.  
- This setup provides durability, retry handling, and message-level fault tolerance.


### 2. Daily Historical Flight Pipeline
- Pulls data from the previous day using the AviationStack API.  
- Converts JSON â†’ Parquet â†’ Iceberg format.  
- Used for analytics, model retraining, and long-term storage.  

### 3. Future Flight Delay Prediction Pipeline
- Fetches flight data **up to 8 days in advance** using the AviationStack API - the **earliest avialable future window** supported by their service.
- Applies a trained XGBoost regression model to predict arrival delays.  
- Outputs both Parquet (for reprocessing) and Excel files (for analysis).  

### 4. Weekly Model Retraining
- Historical Iceberg data is aggregated and used to retrain the XGBoost model weekly.  
- Updated model replaces the previous version and is used by the next weekâ€™s prediction pipeline.

### 5. Airflow DAG Orchestration
- Manages dependencies across:
  - Data ingestion  
  - Data transformation  
  - Feature encoding  
  - Model prediction  
  - **Optional** email dispatch  
- Includes automatic retries and logging for fault tolerance.

---

## ETL Pipeline (Bronze â†’ Silver â†’ Gold)

| Layer | Description | Tools |
|-------|--------------|--------|
| **Bronze** | Raw JSON ingestion from AviationStack API. | Python, Kafka |
| **Silver** | Data cleaning, schema alignment, and type casting. | PySpark |
| **Gold** | Final Iceberg tables and ML-ready Parquet datasets. | Iceberg, PySpark, Parquet |

---

## Setup

### Prerequisites
- Docker + Docker Compose  
- Python 3.9+  
- [AviationStack API key](https://aviationstack.com/)  

### Quickstart

```
git clone https://github.com/ben-grigsby/HermesFlow.git
cd HermesFlow
cp .env.example .env  # Add your API key
docker-compose up --build
```


Then visit:

- Airflow UI: http://localhost:8080

# DAG Scheduling Summary

This document provides an overview of the scheduling logic, execution order, and dependency design of all DAGs within **HermesFlow**.  
Each DAG is orchestrated in **Apache Airflow** to handle data ingestion, transformation, machine learning retraining, and prediction workflows.

---

## Overview

HermesFlow contains three primary DAGs:

1. **Daily Historical Flight Data DAG**
2. **Future Flight Delay Prediction DAG**
3. **Weekly Model Retraining DAG**

These DAGs are designed to complement each other â€” the **daily pipelines** ensure fresh data ingestion and prediction updates, while the **weekly retraining** ensures model relevance and adaptability over time.

---

## 1. Daily Historical Flight Data DAG (`avstack_daily_data_dag`)

### **Purpose**

Consumes and processes flight data from the previous day (T-1) via Kafka consumer streams.
Performs the complete ETL cycle and stores the output in Iceberg for retraining and analytics.

### **Schedule**
| Frequency | Time (UTC) | Airflow Expression | Description |
|------------|-------------|--------------------|--------------|
| Daily | 03:00 | `0 3 * * *` | Runs once daily at 3 AM (UTC) to capture previous dayâ€™s flight records. |

### **Workflow**

1. **Bronze Layer** â€“ Streams AviationStack flight data into **daily_flights** and reads messages while converting them to raw JSON.  
2. **Silver Layer** â€“ Converts JSON to Parquet, performs schema standardization.  
3. **Gold Layer** â€“ Stores processed data into Apache Iceberg tables.  
4. **Logging** â€“ Each step tracked within Airflow for transparency and error recovery.

### **Output**
- `data/bronze/daily/` â†’ Kafka streaming and data processing
- `data/silver/daily/` â†’ Cleaned parquet  
- `data/gold/iceberg/` â†’ Final storage for analytics and ML training  

---

## 2. Future Flight Delay Prediction DAG (`avstack_future_flight_delay_prediction`)

### **Purpose**
Pulls future scheduled flights (`T+8`) and predicts their expected delays using a pre-trained **XGBoost regression model**.  
This DAG ensures the system continuously outputs actionable insights for upcoming flights.

### **Schedule**
| Frequency | Time (UTC) | Airflow Expression | Description |
|------------|-------------|--------------------|--------------|
| Daily | 10:00 | `0 10 * * *` | Runs once daily at 10 AM to forecast flight delays 8 days ahead. |

### **Workflow**
1. **Kafka Producer** â€“ Publishes T+8 flight data to future_flights topic.
2. **Kafka Consumer** â€“ Writes records to Bronze parquet.  
3. **Model Prediction** â€“ Uses latest trained XGBoost model for delay forecasting.  
4. **Output Generation** â€“ Saves both Parquet and Excel outputs for reporting.  
5. **(Optional)** Email Dispatch â€“ Sends delay reports to subscribed users.

### **Output**
- `data/predictions/future_flights/` â†’ Raw predictions in Parquet  
- `data/predictions_excel/` â†’ Readable Excel summaries  

---

## 3. Weekly Model Retraining DAG (`train_xgboost_model`)

### **Purpose**
Retrains the **XGBoost regression model** using the latest historical flight data stored in Iceberg format.  
This ensures continuous improvement of prediction accuracy as new data becomes available.

### **Schedule**
| Frequency | Time (UTC) | Airflow Expression | Description |
|------------|-------------|--------------------|--------------|
| Weekly | Sunday, 04:00 | `0 4 * * 0` | Runs once weekly at 4 AM every Sunday. |

### **Workflow**
1. **Data Extraction** â€“ Pulls aggregated flight records from Iceberg.  
2. **Feature Engineering** â€“ Generates lag, rolling, and encoded variables.  
3. **Model Training** â€“ Trains a new XGBoost model using PySpark ML interface.  
4. **Validation** â€“ Evaluates model performance (MAE, RMSE).  
5. **Deployment** â€“ Replaces existing model in `/data/models/xgboost_flight_delay/`.

### **Output**
- `data/models/xgboost_flight_delay/` â†’ Serialized SparkXGBRegressor model  
- `data/logs/model_training.log` â†’ Metrics and versioning info  

---

## Dependency Flow

The following diagram illustrates the dependency order between DAGs:


```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   avstack_daily_data_dag   â”‚   (Runs daily at 3 AM UTC)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   train_xgboost_model      â”‚   (Runs weekly on Sunday at 5 AM UTC)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ avstack_future_flight_delay_prediction       â”‚   (Runs daily at 2 AM UTC)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Logic:**  
1. The **daily DAG** ensures historical data is fresh and ready for retraining.  
2. The **weekly retrain DAG** updates the model based on that data.  
3. The **future prediction DAG** consumes the latest model and predicts upcoming delays.

---

## Notes on Reliability

- All DAGs are configured with:
  - **`catchup=False`** to avoid retroactive backfills  
  - **Logging and XComs** for consistent inter-task data passing  
  - **Kafka offset tracking** for reliable message consumption
  - **Retries** for transient API or network errors

- The pipelines gracefully handle:
  - Temporary API outages  
  - Slow or malformed responses  
  - Partial data writes  
  - Kafka retries

---

## Summary

| DAG Name | Trigger Time | Frequency | Data Target | Core Output |
|-----------|--------------|------------|--------------|--------------|
| `avstack_daily_data_dag` | 03:00 UTC | Daily | Iceberg | Historical flight data |
| `train_xgboost_model` | 04:00 UTC (Sunday) | Weekly | Models directory | Updated XGBoost model |
| `avstack_future_flight_delay_prediction` | 10:00 UTC | Daily | Parquet + Excel | Future flight delay forecasts |

---

## Future Enhancements

1. Adding in a pipeline that extracts weather data to become an additional model variable and further improve delay prediction accuracy 
2. Update the delay prediction output code to email analysts/schedule planners the prediction status of flights to aid their efforts in mitigating costs caused by delays.

---

## Project Reflection

A deeper analysis of design decisions, trade-offs, and lessons learned can be found in the  
ğŸ“˜ [DEEP_REFLECTION.md](./PROJECT_REFLECTION.md) document.

---

## Author

**Ben Grigsby**  
Statistics & Machine Learning @ UC Davis  
[GitHub](https://github.com/ben-grigsby) â€¢ [LinkedIn](https://linkedin.com/in/ben-grigsby)