[2025-09-16T03:11:57.316+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [queued]>
[2025-09-16T03:11:57.319+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [queued]>
[2025-09-16T03:11:57.319+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-09-16T03:11:57.323+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): run_bronze_load> on 2025-09-15 18:50:00+00:00
[2025-09-16T03:11:57.325+0000] {standard_task_runner.py:60} INFO - Started process 749 to run task
[2025-09-16T03:11:57.326+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'opensky_data_pipeline_dag', 'run_bronze_load', 'scheduled__2025-09-15T18:50:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/opensky_data_pipeline_dag.py', '--cfg-path', '/tmp/tmp23ra073x']
[2025-09-16T03:11:57.327+0000] {standard_task_runner.py:88} INFO - Job 12: Subtask run_bronze_load
[2025-09-16T03:11:57.347+0000] {task_command.py:423} INFO - Running <TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [running]> on host d6bdfb507af9
[2025-09-16T03:11:57.374+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='opensky_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_bronze_load' AIRFLOW_CTX_EXECUTION_DATE='2025-09-15T18:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-09-15T18:50:00+00:00'
[2025-09-16T03:11:57.385+0000] {base.py:83} INFO - Using connection ID 'postgres_default' for task execution.
[2025-09-16T03:11:57.395+0000] {bronze_load.py:30} INFO - Beginning to extract and load data into bronze_info table.
[2025-09-16T03:11:57.952+0000] {bronze_load.py:36} INFO - Completed extracting and loading data int bronze_info table.
[2025-09-16T03:11:57.954+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-09-16T03:11:57.959+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=opensky_data_pipeline_dag, task_id=run_bronze_load, execution_date=20250915T185000, start_date=20250916T031157, end_date=20250916T031157
[2025-09-16T03:11:58.001+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-09-16T03:11:58.011+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-09-16T06:53:39.826+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [queued]>
[2025-09-16T06:53:39.829+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [queued]>
[2025-09-16T06:53:39.829+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-09-16T06:53:39.833+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): run_bronze_load> on 2025-09-15 18:50:00+00:00
[2025-09-16T06:53:39.835+0000] {standard_task_runner.py:60} INFO - Started process 455 to run task
[2025-09-16T06:53:39.836+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'opensky_data_pipeline_dag', 'run_bronze_load', 'scheduled__2025-09-15T18:50:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/opensky_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpe6kic_qi']
[2025-09-16T06:53:39.837+0000] {standard_task_runner.py:88} INFO - Job 10: Subtask run_bronze_load
[2025-09-16T06:53:39.858+0000] {task_command.py:423} INFO - Running <TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [running]> on host 7b6d608462af
[2025-09-16T06:53:39.885+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='opensky_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_bronze_load' AIRFLOW_CTX_EXECUTION_DATE='2025-09-15T18:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-09-15T18:50:00+00:00'
[2025-09-16T06:53:39.895+0000] {base.py:83} INFO - Using connection ID 'postgres_default' for task execution.
[2025-09-16T06:53:39.897+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/etl/bronze/opensky/bronze_load.py", line 27, in insert_into_bronze_ddl
    with open(filepath, "r") as f:
         ^^^^^^^^^^^^^^^^^^^
TypeError: expected str, bytes or os.PathLike object, not NoneType
[2025-09-16T06:53:39.901+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=opensky_data_pipeline_dag, task_id=run_bronze_load, execution_date=20250915T185000, start_date=20250916T065339, end_date=20250916T065339
[2025-09-16T06:53:39.904+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 10 for task run_bronze_load (expected str, bytes or os.PathLike object, not NoneType; 455)
[2025-09-16T06:53:39.934+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-09-16T06:53:39.943+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-09-16T08:29:10.794+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [queued]>
[2025-09-16T08:29:10.797+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [queued]>
[2025-09-16T08:29:10.798+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-09-16T08:29:10.802+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): run_bronze_load> on 2025-09-15 18:50:00+00:00
[2025-09-16T08:29:10.805+0000] {standard_task_runner.py:60} INFO - Started process 829 to run task
[2025-09-16T08:29:10.806+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'opensky_data_pipeline_dag', 'run_bronze_load', 'scheduled__2025-09-15T18:50:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/opensky_data_pipeline_dag.py', '--cfg-path', '/tmp/tmpeslxt6gp']
[2025-09-16T08:29:10.807+0000] {standard_task_runner.py:88} INFO - Job 10: Subtask run_bronze_load
[2025-09-16T08:29:10.827+0000] {task_command.py:423} INFO - Running <TaskInstance: opensky_data_pipeline_dag.run_bronze_load scheduled__2025-09-15T18:50:00+00:00 [running]> on host 64220da1adfe
[2025-09-16T08:29:10.930+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='opensky_data_pipeline_dag' AIRFLOW_CTX_TASK_ID='run_bronze_load' AIRFLOW_CTX_EXECUTION_DATE='2025-09-15T18:50:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-09-15T18:50:00+00:00'
[2025-09-16T08:29:10.957+0000] {bronze_load.py:27} INFO - Loaded 61662 rows from Parquet: /opt/airflow/scripts/opensky/../../data/kafka_parquet/opensky_batch_20250916_082910.parquet
[2025-09-16T08:29:10.957+0000] {bronze_load.py:28} INFO - Beginning to extract and load data into bronze_info table.
[2025-09-16T08:29:10.963+0000] {base.py:83} INFO - Using connection ID 'postgres_default' for task execution.
[2025-09-16T08:29:10.977+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/etl/bronze/opensky/bronze_load.py", line 40, in insert_into_bronze_ddl
    cur.execute(insert_query, full_row)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type json
LINE 24: ...aN'::float, NULL, 'NaN'::float, '4362', false, 0, '["a53eef"...
                                                              ^
DETAIL:  Token "NaN" is invalid.
CONTEXT:  JSON data, line 1: ... 1758011276.0, 1758011276, -78.7309, 42.9394, NaN...

[2025-09-16T08:29:10.981+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=opensky_data_pipeline_dag, task_id=run_bronze_load, execution_date=20250915T185000, start_date=20250916T082910, end_date=20250916T082910
[2025-09-16T08:29:10.984+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 10 for task run_bronze_load (invalid input syntax for type json
LINE 24: ...aN'::float, NULL, 'NaN'::float, '4362', false, 0, '["a53eef"...
                                                              ^
DETAIL:  Token "NaN" is invalid.
CONTEXT:  JSON data, line 1: ... 1758011276.0, 1758011276, -78.7309, 42.9394, NaN...
; 829)
[2025-09-16T08:29:11.027+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-09-16T08:29:11.037+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
